{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da62b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_data\\\\10.jpg', 'image_data\\\\11116.jpg', 'image_data\\\\cock.jpg', 'image_data\\\\gun.jpg']\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_data\\10.jpg\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_data\\11116.jpg\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_data\\cock.jpg\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_data\\gun.jpg\n",
      "[{'image_data\\\\10.jpg': {'drawings': 0.03408496081829071, 'hentai': 0.030753731727600098, 'neutral': 0.05647759139537811, 'porn': 0.8606960773468018, 'sexy': 0.017987744882702827}}, {'image_data\\\\11116.jpg': {'drawings': 0.026670880615711212, 'hentai': 0.02497580088675022, 'neutral': 0.8212873935699463, 'porn': 0.10139939934015274, 'sexy': 0.025666484609246254}}, {'image_data\\\\cock.jpg': {'drawings': 0.06420043855905533, 'hentai': 0.01737922802567482, 'neutral': 0.8439819812774658, 'porn': 0.027503060176968575, 'sexy': 0.04693525284528732}}, {'image_data\\\\gun.jpg': {'drawings': 0.011121034622192383, 'hentai': 0.010665267705917358, 'neutral': 0.9495856165885925, 'porn': 0.004424175247550011, 'sexy': 0.024203896522521973}}]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join, exists, isdir, abspath\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "IMAGE_DIM = 224   # required/default image dimensionality\n",
    "\n",
    "def load_images(image_paths, image_size, verbose=True):\n",
    "   \n",
    "    loaded_images = []\n",
    "    loaded_image_paths = []\n",
    "\n",
    "    if isdir(image_paths):\n",
    "        parent = abspath(image_paths)\n",
    "        image_paths = [join(parent, f) for f in listdir(image_paths) if isfile(join(parent, f))]\n",
    "    elif isfile(image_paths):\n",
    "        image_paths = [image_paths]\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            if verbose:\n",
    "                print(img_path)\n",
    "            image = keras.preprocessing.image.load_img(img_path, target_size=image_size)\n",
    "            image = keras.preprocessing.image.img_to_array(image)\n",
    "            image /= 255\n",
    "            loaded_images.append(image)\n",
    "            loaded_image_paths.append(img_path)\n",
    "        except Exception as ex:\n",
    "            print(\"Image Load Failure: \", img_path, ex)\n",
    "    \n",
    "    return np.asarray(loaded_images), loaded_image_paths\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    if model_path is None or not exists(model_path):\n",
    "    \traise ValueError(\"saved_model_path must be the valid directory of a saved model to load.\")\n",
    "    \n",
    "    # model = tf.keras.models.load_model(model_path)\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "    # model.summary()\n",
    "    #print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def classify(model, input_paths, image_dim=IMAGE_DIM):\n",
    "    \"\"\" Classify given a model, input paths (could be single string), and image dimensionality....\"\"\"\n",
    "    images, image_paths = load_images(input_paths, (image_dim, image_dim))\n",
    "    probs = classify_nd(model, images)\n",
    "    return dict(zip(image_paths, probs))\n",
    "\n",
    "\n",
    "def classify_nd(model, nd_images):\n",
    "    \"\"\" Classify given a model, image array (numpy)....\"\"\"\n",
    "\n",
    "    model_preds = model.predict(nd_images)\n",
    "    # preds = np.argsort(model_preds, axis = 1).tolist()\n",
    "    \n",
    "    categories = ['drawings', 'hentai', 'neutral', 'porn', 'sexy']\n",
    "\n",
    "    probs = []\n",
    "    for i, single_preds in enumerate(model_preds):\n",
    "        single_probs = {}\n",
    "        for j, pred in enumerate(single_preds):\n",
    "            single_probs[categories[j]] = float(pred)\n",
    "        probs.append(single_probs)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def main():   \n",
    "    img_paths  = glob.glob('image_data/*.jpg')\n",
    "    predictions = []\n",
    "    print(img_paths)\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        model = load_model(\"Nudity-Detection-Model.h5\")\n",
    "        model.compile()\n",
    "        image_preds = classify(model, img_path, IMAGE_DIM)\n",
    "        predictions.append(image_preds)\n",
    "    \n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2aaff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
